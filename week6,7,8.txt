
week6 digit recognnization
-----------------------------
#import modules
import tensorflow as tf
import matplotlib.pyplot as plt
%matplotlib inline
import numpy as np
from tensorflow import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten

# the data, split between train and test sets
(xtrain, ytrain), (xtest, ytest) = mnist.load_data()

xtrain=xtrain/255
xtest=xtest/255

xtrainflat = xtrain.reshape(len(xtrain),28*28)
xtestflat = xtest.reshape(len(xtest),28*28)
plt.matshow(xtest[70])

model = Sequential([Dense(100,input_shape=(784,),activation='relu'), Dense(10,activation='softmax')])
model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])
model.fit(xtrainflat,ytrain,epochs=5)

model.evaluate(xtestflat,ytest)
ypredict= model.predict(xtestflat)
np.argmax(ypredict[70])










#WEEK 7 Credit card fraud detection

------------------------------------------

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_validate
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif
from scikitplot.metrics import plot_confusion_matrix
data = pd.read_csv("C:\\Users\\Administrator\\Downloads\\arch\\creditcard.csv")
data.head()
print("Column names : " , list(data))
print("Total columns : " , len(list(data)))
n_genuine = len(data[data["Class"] == 0])
n_fraud = len(data[data["Class"] == 1])
print("Number of genuine transactions : " , n_genuine)
print("Number of fraudulent transactions : " , n_fraud)
plt.pie([n_genuine, n_fraud] , labels=['Genuine', 'Fraud'], radius=1)
plt.show()
X, y = data.iloc[:,:-1], data.iloc[:,-1]
## check features values
X.head()
## check target values
y.head()
k = 10
k_best = SelectKBest(f_classif, k=k)
k_best.fit(X,y)
# Mask returns a boolean array which has value 1 for every selected feature and value 0 for not selected ones
mask = k_best.get_support()
not_mask = np.logical_not(mask)

all_features = np.array(list(X))

# separating the best 10 features onbtained from bad ones
best_features = all_features[mask]
bad_features = all_features[not_mask]

print('Best features : ', best_features)
print('Bad features : ', bad_features)
# Dropping the bad features from the features dataframe X 
X = X.drop(bad_features, axis=1)
X.head()
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)
# Creating a Gaussian Naive Bayes object
nb = GaussianNB()
# cv_results stores the train score and estimator 
cv_results = cross_validate(nb, x_train, y_train, cv=10, scoring='recall',return_train_score = True)
print("Training scores from each fold : ", cv_results['train_score'])
# iteration with maximum train_score is selected for training model
max_score_index = np.argmax(cv_results['train_score'])
nb1=GaussianNB()
nb1.fit(x_train,y_train)
nb1.score(x_train,y_train)
y_pred=nb1.predict(x_test)
y_pred
from sklearn.metrics import accuracy_score

print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))
y_pred_train = nb1.predict(x_train)

y_pred_train
print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))
# print the scores on training and test set

print('Training set score: {:.4f}'.format(nb1.score(x_train, y_train)))

print('Test set score: {:.4f}'.format(nb1.score(x_test, y_test)))
from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred)

print('Confusion matrix\n\n', cm)

print('\nTrue Positives(TP) = ', cm[0,0])

print('\nTrue Negatives(TN) = ', cm[1,1])

print('\nFalse Positives(FP) = ', cm[0,1])

print('\nFalse Negatives(FN) = ', cm[1,0])










week8
#WEEK 8 Text classification using Naive bayes
----------------------------------------------------

import numpy as np, pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline
from sklearn.metrics import confusion_matrix, accuracy_score
sns.set() # use seaborn plotting style
# Load the dataset
data = fetch_20newsgroups()
# Get the text categories
text_categories = data.target_names
# define the training set
train_data = fetch_20newsgroups(subset="train", categories=text_categories)
# define the test set
test_data = fetch_20newsgroups(subset="test", categories=text_categories)
print("We have {} unique classes".format(len(text_categories)))
print("We have {} training samples".format(len(train_data.data)))
print("We have {} test samples".format(len(test_data.data)))
# letâ€™s have a look as some training data
print(test_data.data[5])
# Build the model
model = make_pipeline(TfidfVectorizer(), MultinomialNB())
# Train the model using the training data
model.fit(train_data.data, train_data.target)
# Predict the categories of the test data
predicted_categories = model.predict(test_data.data)
print(np.array(test_data.target_names)[predicted_categories])
# plot the confusion matrix
mat = confusion_matrix(test_data.target, predicted_categories)
sns.heatmap(mat.T, square = True, annot=True, fmt = "d", xticklabels=train_data.target_names,yticklabels=train_data.target_names)
plt.xlabel("true labels")
plt.ylabel("predicted label")
plt.show()
print("The accuracy is {}".format(accuracy_score(test_data.target, predicted_categories)))
# custom function to have fun
def my_predictions(my_sentence, model):
    all_categories_names = np.array(data.target_names)
    prediction = model.predict([my_sentence])
    return all_categories_names[prediction]
my_sentence = "jesus"
print(my_predictions(my_sentence, model))
my_sentence = "Are you an atheist?"
print(my_predictions(my_sentence, model))
my_sentence = "i like ride"
print(my_predictions(my_sentence, model))








